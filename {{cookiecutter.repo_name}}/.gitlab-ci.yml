image: dahanna/python:alpine-miniconda-3.7-git-tox

{% if cookiecutter.ci_https_proxy != "no" -%}
variables:
  # HTTP_PROXY is used to pull docker images.
  HTTP_PROXY: {{cookiecutter.ci_https_proxy}}
  # HTTPS_PROXY is used to install Python packages such as tox.
  HTTPS_PROXY: {{cookiecutter.ci_https_proxy}}
  # If we don't include NO_PROXY, we will get "fatal unable to update url base from redirection"
  # when trying to fetch the gitlab-ci-token.
  NO_PROXY: 127.0.0.1,localhost,.lan,.local,.home,/var/run/docker.sock,{{cookiecutter.repo_hosting_domain}}
{%- endif %}

default:
  before_script:
    - right_after_pull_docker_image=$(date +%s)
    - echo $(whoami)
    - echo $USER

    # If we need to apk add openssh-client, then we will need HTTPS_PROXY set first.
    # This potentially leads to a problem if we need SSH to access the ETC_ENVIRONMENT_LOCATION.
    # The ETC_ENVIRONMENT_LOCATION is not generally intended for secret keys like the SSH_PRIVATE_KEY.
    - if [ -z ${ETC_ENVIRONMENT_LOCATION+ABC} ]; then echo "ETC_ENVIRONMENT_LOCATION is unset, so assuming you do not need environment variables set.";
      else
    # All of this will be skipped unless you set ETC_ENVIRONMENT_LOCATION in GitLab.
    # Strictly speaking, this serves the same function as .profile, being run before everything else.
    # You *could* put arbitrary shell commands in the file, but the intended purpose is
    # to save on manual work by allowing you to set only one GitLab variable that points
    # to more variables to set.
    # Special note if the environment file is used to set up a proxy with HTTPS_PROXY...
    # $ETC_ENVIRONMENT_LOCATION must be a location that we can access *before* setting up the proxy variables.
    - echo $ETC_ENVIRONMENT_LOCATION
    # We do not want the script to hang waiting for a password if the private key is rejected.
    - mkdir --parents ~/.ssh
    - echo "PasswordAuthentication=no" >> ~/.ssh/config
    - echo $SSH_PRIVATE_KEY > SSH.PRIVATE.KEY # If SSH_PRIVATE_KEY is unset, this will just be empty.
    - wget $ETC_ENVIRONMENT_LOCATION --output-document environment.sh --no-clobber || curl --verbose $ETC_ENVIRONMENT_LOCATION --output environment.sh || scp -i SSH.PRIVATE.KEY $ETC_ENVIRONMENT_LOCATION environment.sh
    - rm SSH.PRIVATE.KEY
    - cat environment.sh
    - set -o allexport
    - source environment.sh
    - set +o allexport
    - fi

    - if [ -z ${SSH_PRIVATE_KEY+ABC} ]; then echo "SSH_PRIVATE_KEY is unset, so assuming you do not need SSH set up.";
      else
    # All of this will be skipped unless you set SSH_PRIVATE_KEY as a variable at https://{{ cookiecutter.repo_hosting_domain }}/{{ cookiecutter.repo_username }}/{{ cookiecutter.repo_name }}/-/settings/ci_cd
    {% raw -%}
    - if [ ${#SSH_PRIVATE_KEY} -le 5 ]; then echo "SSH_PRIVATE_KEY looks far too short, something is wrong"; fi
    {%- endraw %}
    - apk add openssh-client || apt-get install --assume-yes openssh-client
    - echo "adding openssh-client took $(( $(date +%s) - right_after_pull_docker_image)) seconds"

    # ssh-agent -s starts the ssh-agent and then outputs shell commands to run.
    - eval $(ssh-agent -s)

    ##
    ## Add the SSH key stored in SSH_PRIVATE_KEY variable to the agent store.
    ## We're using tr to fix line endings which makes ed25519 keys work
    ## without extra base64 encoding.
    ## We use -d because the version of tr on alpine does not recognize --delete.
    ## https://gitlab.com/gitlab-examples/ssh-private-key/issues/1#note_48526556
    ##
    - echo "$SSH_PRIVATE_KEY" | tr -d '\r' | ssh-add -

    ##
    ## Sometimes we may want to install directly from a git repository.
    ## Using up-to-the-minute updates of dependencies in our own tests alerts
    ## us if something breaks with the latest version of a dependency, even if
    ## that dependency has not made a new release yet.
    ## In order to pip install directly from git repositories,
    ## we need to whitelist the public keys of the git servers.
    ## You may want to add more lines for the domains of any other git servers
    ## you want to install dependencies from (which may or may not include the
    ## server that hosts your own repo).
    ## Similarly, if you want to push to a secondary repo as part of your build
    ## (as how cookiecutter-pylibrary builds examples and
    ## pushes to python-nameless), ssh will need to be allowed to reach that
    ## server.
    ## https://docs.travis-ci.com/user/ssh-known-hosts/
    ## https://discuss.circleci.com/t/add-known-hosts-on-startup-via-config-yml-configuration/12022/2
    ## Unfortunately, there seems to be no way to use ssh-keyscan on a server
    ## that you can only reach through a proxy. Thus, a simple
    ## ssh-keyscan -t rsa github.com gitlab.com >> ~/.ssh/known_hosts
    ## will fail. As a workaround, I just grabbed their public keys now and
    ## included them. These might go stale eventually, I'm not sure.
    ##
    - mkdir --parents ~/.ssh
    - echo "# github.com:22 SSH-2.0-babeld-f345ed5d\n" >> ~/.ssh/known_hosts
    - echo "github.com ssh-rsa AAAAB3NzaC1yc2EAAAABIwAAAQEAq2A7hRGmdnm9tUDbO9IDSwBK6TbQa+PXYPCPy6rbTrTtw7PHkccKrpp0yVhp5HdEIcKr6pLlVDBfOLX9QUsyCOV0wzfjIJNlGEYsdlLJizHhbn2mUjvSAHQqZETYP81eFzLQNnPHt4EVVUh7VfDESU84KezmD5QlWpXLmvU31/yMf+Se8xhHTvKSCZIFImWwoG6mbUoWf9nzpIoaSjB+weqqUUmpaaasXVal72J+UX2B+2RPW3RcT0eOzQgqlJL3RKrTJvdsjE3JEAvGq3lGHSZXy28G3skua2SmVi/w4yCE6gbODqnTWlg7+wC604ydGXA8VJiS5ap43JXiUFFAaQ==\n" >> ~/.ssh/known_hosts
    - echo "# gitlab.com:22 SSH-2.0-OpenSSH_7.2p2 Ubuntu-4ubuntu2.8\n" >> ~/.ssh/known_hosts
    - echo "gitlab.com ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCsj2bNKTBSpIYDEGk9KxsGh3mySTRgMtXL583qmBpzeQ+jqCMRgBqB98u3z++J1sKlXHWfM9dyhSevkMwSbhoR8XIq/U0tCNyokEi/ueaBMCvbcTHhO7FcwzY92WK4Yt0aGROY5qX2UKSeOvuP4D6TPqKF1onrSzH9bx9XUf2lEdWT/ia1NEKjunUqu1xOB/StKDHMoX4/OKyIzuS0q/T1zOATthvasJFoPrAjkohTyaDUz2LN5JoH839hViyEG82yB+MjcFV5MU3N1l1QL3cVUCh93xSaua1N85qivl+siMkPGbO5xR/En4iEY6K2XPASUEMaieWVNTRCtJ4S8H+9\n" >> ~/.ssh/known_hosts
    - fi

    # When we get the environment file, it might have some servers for us to whitelist.
    # Alternatively, maybe there was no ETC_ENVIRONMENT_LOCATION
    # and SERVERS_TO_WHITELIST_FOR_SSH is just manually set as a GitLab variable.
    # If SSH_PRIVATE_KEY is not set, then we will silently ignore SERVERS_TO_WHITELIST_FOR_SSH,
    # since without a key of some kind we cannot use SSH anyway.
    # This allows us to share around a common ETC_ENVIRONMENT_LOCATION that includes SERVERS_TO_WHITELIST_FOR_SSH,
    # even though only some people actually use SSH for anything.
    - if [ -z ${SERVERS_TO_WHITELIST_FOR_SSH+ABC} ] || [ -z ${SSH_PRIVATE_KEY+ABC} ]; then echo "SERVERS_TO_WHITELIST_FOR_SSH and SSH_PRIVATE_KEY are not both set, so assuming you do not need any servers whitelisted for SSH.";
      else
    - echo $SERVERS_TO_WHITELIST_FOR_SSH
    - mkdir --parents ~/.ssh
    - ssh-keyscan -t rsa $SERVERS_TO_WHITELIST_FOR_SSH >> ~/.ssh/known_hosts
    - fi

    - if [ -d /opt/conda ]; then
    - CONDA_DIR=/opt/conda
    - PATH=$CONDA_DIR/bin:$PATH
    - source activate test-env
      ; else
      echo "/opt/conda was not found on this container"
      ; fi

    - pip install --upgrade pip
    - if [ -z ${PROXY_CA_PEM+ABC} ]; then echo "PROXY_CA_PEM is unset, so assuming you do not need a merged CA certificate set up.";
      else
    # All of this will be skipped unless you set PROXY_CA_PEM in GitLab.
    # You will usually want to cat your.pem | xclip and paste it in as a File on GitLab.
    # See the KUBE_CA_PEM example at https://docs.gitlab.com/ee/ci/variables/README.html#variable-types
    - right_before_pull_cert=$(date +%s)
    {% raw -%}
    - if [ ${#PROXY_CA_PEM} -ge 1024 ]; then
    {%- endraw %}
    - echo "The PROXY_CA_PEM filename looks far too long, did you set it as a Variable instead of a File?"
    # If it's the full certificate rather than a filename, write it to a file and save the file name.
    - echo "$PROXY_CA_PEM" > tmp-proxy-ca.pem
    # The quotes are very important here; echo $PROXY_CA_PEM will destroy the
    # newlines, and requests will (silently!) fail to parse the certificate,
    # leading to SSLError SSLCertVerificationError 'certificate verify failed self signed certificate in certificate chain (_ssl.c:1076)'
    - PROXY_CA_PEM=tmp-proxy-ca.pem
      ; fi
    # If some of the links in your documentation require a special PEM to verify,
    # then sphinx -b linkcheck will fail without that PEM.
    # But setting REQUESTS_CA_BUNDLE to that PEM will cause other links to fail,
    # because the runner will only accept that PEM, not the defaults.
    # Therefore you will usually want to bundle all certificates together with
    - python --version
    # cat `python -c "import requests; print(requests.certs.where())"` ~/your.pem > ~/bundled.pem
    # pip uses requests, but not the normal requests.
    # pip uses a vendored version of requests, so that pip will still work if anything goes wrong with your requests installation.
    # We find where that vendored version of requests keeps its certs and merge in the cert from PROXY_CA_PEM.
    # On some systems, we might need to try the import twice, and the first time, it will fail with an AttributeError.
    # Therefore we need a block to suppress the AttributeError, which requires a colon.
    # But that causes parsing of .gitlab-ci.yml to fail with "before_script config should be an array of strings",
    # so we need to wrap the entire line in ''.
    # https://gitlab.com/gitlab-org/gitlab-foss/merge_requests/5481
    - 'echo -e "import contextlib\nwith contextlib.suppress(AttributeError): import pip._vendor.requests\nfrom pip._vendor.requests.certs import where\nprint(where())" | python'
    - 'cat `echo -e "import contextlib\nwith contextlib.suppress(AttributeError): import pip._vendor.requests\nfrom pip._vendor.requests.certs import where\nprint(where())" | python` $PROXY_CA_PEM > bundled.pem'
    - ls bundled.pem
    # In the unlikely event that the image does not have Python available, the above command may silently fail to write bundled.pem.
    # Thus we check python --version above and double-check that bundled.pem exists with ls.
    - export REQUESTS_CA_BUNDLE="${PWD}/bundled.pem"
    # We include the working directory PWD so that REQUESTS_CA_BUNDLE can still be found from another directory.
    # This seems to matter when activating and using a conda environment, for some reason.
    - ls $REQUESTS_CA_BUNDLE
    - echo "Merging the certificate bundle took $(( $(date +%s) - right_before_pull_cert)) seconds total"
    - fi

    ##
    ## With all our proxy variables and certificates in place, we should now be
    ## able to install from repositores, and optionally push to repositories.
    ## Optionally, if you will be making any git commits, set the user name and
    ## email.
    ##
    #- git config --global user.email "{{ cookiecutter.email }}"
    #- git config --global user.name "{{ cookiecutter.full_name }}"

    # With --sitepackages, we can save time by installing once
    # for both regular tests and documentation checks.
    # Building the documentation also requires the package to be importable,
    # if using autodoc and its descendants.
    # Note that the installation will be repeated, once for each job.
    # The installation still will not be shared across jobs.
    # This is not ideal, but if installation takes a very long time, then you
    # might want to use a Docker image with most of your dependencies already
    # installed.

    - python3 --version || echo "python3 is not found by that name."
    # If the docs include a Jupyter notebook, we need ipykernel to build the docs (including running doctests).
    # Without ipykernel, attempting to --execute Jupyter notebooks when building the documentation will fail with
    # No such kernel named python3
    - pip install ipykernel
    - python -m ipykernel install
    - pip install ipywidgets # without this, module 'plotly.graph_objects' has no attribute 'FigureWidget'

    - right_before_pip_install=$(date +%s)
    - pip install .
    - echo "Installing your package took $(( $(date +%s) - right_before_pip_install)) seconds total"

# In general we want to use tox -e docs, but GitLab.com will not deploy Pages
# if the pages build fails.
# The pages build will fail if you use tox -e docs with a link to your GitLab
# Pages documentation that is not yet deployed, because tox -e docs includes
# sphinx-build -b linkcheck. So the pages will never get deployed...
# That's why we deploy pages with no checks here.
# The tests will still run linkcheck on the documentation.
# Since "It may take up to 30 minutes before the site is available after the
# first deployment." (per GitLab), the tests will still fail for a little
# while.
pages:
  tags:
  - docker
  stage: build
  # On GitLab, the stages are build->test->deploy.
  # If the test stage fails, the deploy stage is skipped.
  script:
  - pip install -r docs/requirements.txt

  # WordPress rejects uploading these kinds of files, but we can host a simple conda channel on GitLab Pages.
  - ls /bin/sh
  - ls /bin
  - python -c "import sys; print(sys.platform)"
  - if command -v conda; then echo "conda found"; else echo "conda not found"; fi
  - if command -v conda; then
  - right_before_conda_build=$(date +%s)
  - conda info
  - apk add bash
  - mkdir docs/_static
  - mkdir docs/_static/conda-channel
  - mkdir docs/_static/conda-channel/linux-64
  # $CONDA_DIR does not contain conda-bld
  # Adding --bootstrap pointed at an environment containing all of the requirements (obtained by conda installing python-nameless and then conda uninstalling python-nameless) does not seem to reduce build time at all.
  # Resource usage summary Total time 0:01:13.5 versus Resource usage summary Total time 0:01:12.3
  - conda build conda.recipe --channel conda-forge --output-folder docs/_static/conda-channel/ --no-test
  - echo "Building the conda package took $(( $(date +%s) - right_before_conda_build)) seconds total"
  - ls docs/_static/conda-channel/
  - ls docs/_static/conda-channel/linux-64/
  - conda convert `ls docs/_static/conda-channel/linux-64/*.tar.bz2` --platform all --output-dir docs/_static/conda-channel/
  # conda index doesn't seem to actually make any additional files beyond what conda build already makes
  - conda index docs/_static/conda-channel/
    ; else
    echo "conda not found in this container, so not building a conda package."
    ; fi

  - sphinx-build -E -b html docs dist/docs

  - if command -v conda; then
  - mv docs/_static/conda-channel dist/docs/_static
    ; fi

  - mv dist/docs/ public/
  artifacts:
    paths:
    - public
  only:
  - master

test:
  tags:
  - docker
  stage: test
  script:
  # apk add any needed packages not included in the image.
  # check-manifest, used in tox -e check, requires git,
  # so we need to either use an image that includes git or
  # apk add git here.
  # If using an image that does not include tox, we will
  # need to pip install tox here.
  - git --version
  - python --version
  - python2 --version || echo "python2 is not installed."
  - virtualenv --version
  - pip --version
  - python -m sphinx --version # linkcheck can spuriously fail on old versions of sphinx.
  - pip install --upgrade sphinx
  - tox --version
  - uname --all
  - lsb_release --all || echo "lsb_release is not supported on this host."
  - start_tox=$(date +%s)
  # When testing locally, we might not want to set sitepackages=true,
  # because the local machine might have all kinds of weird things in the
  # environment. But for continuous integration, we do want sitepackages=true,
  # because it allows us to use a Docker image with some packages already
  # installed to accelerate testing.
  - tox --sitepackages
  - echo "tox tests took $(( $(date +%s) - start_tox)) seconds"
  - echo "Everything after pulling the Docker image took $(( $(date +%s) - right_after_pull_docker_image)) seconds total"

